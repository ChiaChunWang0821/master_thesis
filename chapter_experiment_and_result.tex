\documentclass[class=NCU_thesis, crop=false]{standalone}
\begin{document}

\chapter{實驗設計與結果}

\section{臉部偵測準確度實驗}
\subsection{實驗目的與設計}
在收集嬰兒臉部資料集時，
需針對嬰兒影像擷取出臉部範圍，
進而後續之臉部遮擋辨識階段。

因此，本實驗使用3.3.1節之嬰兒姿勢資料集，
分析OpenCV~\cite{goyal_face_2017}
、SSD~\cite{ye_face_2021}
、MTCNN~\cite{zhang_joint_2016}
及RetinaFace~\cite{deng_retinaface_2020}
等臉部偵測演算法其臉部擷取之準確度，
以驗證可應用於本系統之演算法。

\subsection{實驗評估方式}
本實驗為驗證臉部偵測演算法應用於本系統之可行性，
針對四項演算法之偵測準確度進行比較，
將嬰兒臉部偵測結果影像進行分類標註，
以計算出各演算法之accuracy、precision及recall。

\subsection{實驗結果與分析}
根據實驗結果，
OpenCV~\cite{goyal_face_2017}及SSD~\cite{ye_face_2021}將多數影像皆誤判為無臉（False），
亦即影像中有嬰兒臉部畫面但演算法未偵測之，
故此部分僅關注判斷為有臉（True）之數據統計，
詳細實驗結果請見\cref{table:table-opencv}及\cref{table:table-ssd}。
而MTCNN~\cite{zhang_joint_2016}及RetinaFace~\cite{deng_retinaface_2020}之實驗結果，
請見\cref{table:table-mtcnn}及\cref{table:table-retinaface}。
\begin{table}[h]
    \centering
    \caption{OpenCV~\cite{goyal_face_2017}偵測嬰兒臉部結果}
    \label{table:table-opencv}
    \begin{tabular}{ccc}
    \hline
     & True（預測有臉）& False（預測無臉）\\
    \hline
    True & \multirow{2}{*}{2882} & \multirow{4}{*}{11809} \\
    （實際有臉）& & \\
    False & \multirow{2}{*}{725} & \\
    （實際無臉）&  & \\
    \hline
    \end{tabular}
\end{table}

\begin{table}[h]
    \centering
    \caption{SSD~\cite{ye_face_2021}偵測嬰兒臉部結果}
    \label{table:table-ssd}
    \begin{tabular}{ccc}
    \hline
     & True（預測有臉）& False（預測無臉）\\
    \hline
    True & \multirow{2}{*}{4830} & \multirow{4}{*}{10581} \\
    （實際有臉）& & \\
    False & \multirow{2}{*}{5} & \\
    （實際無臉）&  & \\
    \hline
    \end{tabular}
\end{table}

\begin{table}[h]
    \centering
    \caption{MTCNN~\cite{zhang_joint_2016}偵測嬰兒臉部結果}
    \label{table:table-mtcnn}
    \begin{tabular}{ccc}
    \hline
     & True（預測有臉）& False（預測無臉）\\
    \hline
    True & \multirow{2}{*}{9361} & \multirow{2}{*}{994} \\
    （實際有臉）& & \\
    False & \multirow{2}{*}{517} & \multirow{2}{*}{4544} \\
    （實際無臉）&  & \\
    \hline
    Total & \textbf{9878} & \textbf{5538} \\
    \hline
    \end{tabular}
\end{table}

\begin{table}[h]
    \centering
    \caption{RetinaFace~\cite{deng_retinaface_2020}偵測嬰兒臉部結果}
    \label{table:table-retinaface}
    \begin{tabular}{ccc}
    \hline
     & True（預測有臉）& False（預測無臉）\\
    \hline
    True & \multirow{2}{*}{12925} & \multirow{2}{*}{11} \\
    （實際有臉）& & \\
    False & \multirow{2}{*}{33} & \multirow{2}{*}{2447} \\
    （實際無臉）&  & \\
    \hline
    Total & \textbf{12958} & \textbf{2458} \\
    \hline
    \end{tabular}
\end{table}

再經計算後，
四項演算法之accuracy、precision及recall值如下：
\begin{enumerate}
    \item OpenCV~\cite{goyal_face_2017}：由於多數影像皆誤判為無臉（False），故僅計算其precision為79.90\%。
    \item SSD~\cite{ye_face_2021}：由於多數影像皆誤判為無臉（False），故僅計算其precision為99.90\%。
    \item MTCNN~\cite{zhang_joint_2016}：accuracy為90.20\%、precision為94.76\%以及recall為90.93\%。
    \item RetinaFace~\cite{deng_retinaface_2020}：accuracy為99.78\%、precision為99.75\%以及recall為99.91\%。
\end{enumerate}

因此，
透過本實驗結果可得出選用RetinaFace演算法~\cite{deng_retinaface_2020}進行嬰兒臉部偵測，
可擁有較佳的偵測準確度。

\section{臉部偵測執行時間實驗}
\subsection{實驗目的與設計}
本研究進行嬰兒臉部偵測除了考量準確度外，
亦希望提升整體系統之執行速度。

因此，本實驗使用3.3.1節之嬰兒姿勢資料集，
分析OpenCV~\cite{goyal_face_2017}
、SSD~\cite{ye_face_2021}
、MTCNN~\cite{zhang_joint_2016}
及RetinaFace~\cite{deng_retinaface_2020}
等臉部偵測演算法之執行時間，
以驗證適合本系統之演算法。

\subsection{實驗評估方式}
本實驗為驗證臉部偵測演算法應用於系統之可行性，
將針對四項演算法之執行時間進行比較，
透過計算演算法偵測共15416張影像之資料集所花費的時間，
得以算出各演算法平均偵測一張影像之執行時間。

\subsection{實驗結果與分析}
OpenCV~\cite{goyal_face_2017}
、SSD~\cite{ye_face_2021}
、MTCNN~\cite{zhang_joint_2016}
及RetinaFace~\cite{deng_retinaface_2020}
四項演算法偵測15416張影像之詳細實驗結果如下：
\begin{enumerate}
    \item OpenCV~\cite{goyal_face_2017}：共18分01.78秒，平均每張影像需0.07秒。
    \item SSD~\cite{ye_face_2021}：共9分17.26秒，平均每張影像需0.04秒。
    \item MTCNN~\cite{zhang_joint_2016}：共2小時8分22.05秒，平均每張影像需0.50秒。
    \item RetinaFace~\cite{deng_retinaface_2020}：共5小時42分2.10秒，平均每張影像需1.33秒。
\end{enumerate}

因此，
透過本實驗結果可得出使用SSD演算法~\cite{ye_face_2021}進行嬰兒臉部偵測，
將可擁有較佳的偵測速度。

而綜觀4.1節及4.2節之實驗結果，
若系統欲擁有較佳的執行速度又兼具偵測準確度，
可得出以下結論：
先使用SSD演算法~\cite{ye_face_2021}偵測嬰兒臉部，
雖然此方法在許多狀況未能如期找到嬰兒臉部範圍，
但其準確度很高，
故能利用此算法之時間優勢；
而為補足此方法召回率不足之缺失，
若SSD演算法~\cite{ye_face_2021}找不到嬰兒臉部時，
則接續使用RetinaFace演算法~\cite{deng_retinaface_2020}，
利用其正確率及準確率皆高之優點進行嬰兒臉部偵測。

\section{臉部遮擋辨識實驗}
\subsection{實驗目的與設計}
本系統為偵測嬰兒臉部是否遭非奶嘴之異物遮擋，
使用3.2節之資料集以ResNet50~\cite{he_deep_2016}
訓練模型，
並透過驗證集進行模型驗證。

程式實作中，
網路訓練回合數為20，
設定影像資料大小為224x224，
包含三個類別（臉部無遮擋之安全狀態、臉部遭奶嘴遮擋及臉部遭異物遮擋之危險狀態），
且透過data augmentation技術生成訓練及測試資料，
輸出層使用softmax作為激發函數，
並使用Adam作為優化器且將學習率設為0.000001以進行微調。

\subsection{實驗結果分析}
本實驗訓練之模型其最終訓練準確率達98.06\%，
而測試準確率達99.43\%，
詳細訓練結果請見\cref{fig:fig-result-face-occlusion}。
\fig[1][fig:fig-result-face-occlusion][!hbt]{fig-result-face-occlusion.png}[臉部辨識訓練結果][臉部辨識訓練結果]

接著，再使用342張之驗證集影像進行模型驗證，
所有影像皆辨識正確，
其混淆矩陣如\cref{fig:fig-confusion-matrix-face-occlusion}。
\fig[0.6][fig:fig-confusion-matrix-face-occlusion][!hbt]{fig-confusion-matrix-face-occlusion.png}[臉部遮擋辨識模型之混淆矩陣]

\section{姿勢辨識實驗}
\subsection{實驗目的與設計}
本系統為辨識嬰兒姿勢是否處於危險狀態，
使用3.3節之資料集以ResNet50~\cite{he_deep_2016}
訓練模型，
並透過驗證集進行模型驗證。

程式實作中，
網路訓練回合數為20，
設定影像資料大小為224x224，
包含四個類別（正躺、趴躺、坐姿及站立），
且透過data augmentation技術生成訓練及測試資料，
輸出層使用softmax作為激發函數，
並使用Adam作為優化器且將學習率設為0.000001以進行微調。

\subsection{實驗結果分析}
本實驗訓練之模型其最終訓練準確率達99.45\%，
而測試準確率達99.71\%，
詳細訓練結果請見\cref{fig:fig-result-four-classes}。
\fig[1][fig:fig-result-four-classes][!hbt]{fig-result-four-classes.png}[姿勢辨識訓練結果][姿勢辨識訓練結果]

接著，再使用744張之驗證集影像進行模型驗證，
包含了五張類別辨識錯誤的影像，
其混淆矩陣如\cref{fig:fig-confusion-matrix-four-classes}。
辨識錯誤之五張影像中，
有三張將坐姿誤判為趴躺姿勢，
推測原因為嬰兒雖呈現坐姿，
但上半身貼近其腿部（如\cref{fig:fig-error-four-classes}
），而導致誤判。
\fig[0.8][fig:fig-confusion-matrix-four-classes][!hbt]{fig-confusion-matrix-four-classes.png}[姿勢辨識模型之混淆矩陣]
\fig[0.6][fig:fig-error-four-classes][!hbt]{fig-error-four-classes.jpg}[姿勢辨識錯誤之影像：坐姿誤判為趴躺]

\section{影片危險偵測實驗}
\subsection{實驗目的與設計}
本實驗為驗證此系統能基於嬰兒影像進行危險監測，
利用網路之真實嬰兒影片，
包含不同之拍攝視角、嬰兒樣貌及狀態等，
實驗臉部遮擋辨識模型與姿勢辨識模型之準確性。

\subsection{實驗評估方式}
本實驗透過輸出每幀影像之臉部遮擋及姿勢辨識結果，
計算其accuracy、precision及recall，
以驗證此二模型得以應用在監測嬰兒危險情境。

\subsection{實驗結果分析}
本實驗影片為嬰兒正躺於畫面中，
並包含使用奶嘴及未使用奶嘴之情境，
共切成3374幀影像，
將未拍攝到嬰兒畫面之影像刪除後，
剩餘3307張嬰兒影像進行辨識。

首先，
姿勢辨識的部分，
包含了278張誤判為趴躺姿勢的影像，
推測原因為嬰兒身體遭棉被遮擋（如\cref{fig:fig-error-video-posture}），
而只拍攝到露出的嬰兒臉部，
故造成姿勢辨識錯誤，
其混淆矩陣如\cref{fig:fig-confusion-matrix-video-posture}。
\fig[0.6][fig:fig-error-video-posture][!hbt]{fig-error-video-posture.jpg}[姿勢辨識錯誤之影像：正躺誤判為趴躺]
\fig[0.8][fig:fig-confusion-matrix-video-posture][!hbt]{fig-confusion-matrix-video-posture.png}[實驗影片之姿勢辨識混淆矩陣]

其次，
臉部遮擋辨識的部分，
包含36張嬰兒臉部未被偵測之影像（如\cref{fig:fig-error-video-no-face}），
其中多張影像類別應為嬰兒正在使用奶嘴或安全狀態，
但誤判為遭異物遮蔽之警示狀態，
推測原因為影像中之奶嘴或嬰兒臉部遭手部等遮擋（如\cref{fig:fig-error-video-face}），
而誤判為類別，
其混淆矩陣如\cref{fig:fig-confusion-matrix-video-face}。
\fig[0.6][fig:fig-error-video-no-face][!hbt]{fig-error-video-no-face.jpg}[未偵測嬰兒臉部之影像]
\fig[0.4][fig:fig-error-video-face][!hbt]{fig-error-video-face.jpg}[臉部遮擋誤判之為警示狀態]
\fig[0.8][fig:fig-confusion-matrix-video-face][!hbt]{fig-confusion-matrix-video-face.png}[實驗影片之臉部遮擋辨識混淆矩陣]

\end{document}