\documentclass[class=NCU_thesis, crop=false]{standalone}
\begin{document}

\chapter{實驗設計與結果}

\section{嬰兒臉部偵測實驗}
\subsection{實驗目的與設計}
在收集嬰兒臉部資料集時，
需針對嬰兒影像擷取出臉部範圍，
進而後續之臉部遮擋辨識階段。

因此，本實驗使用3.3節之嬰兒姿勢資料集，
就OpenCV~\cite{goyal_face_2017}
、SSD~\cite{ye_face_2021}
、MTCNN~\cite{zhang_joint_2016}
及RetinaFace~\cite{deng_retinaface_2020}
等臉部偵測演算法，
分析其執行時間及臉部擷取準確度進行比較，
以驗證適合本系統之演算法。

\subsection{實驗評估方式}
本實驗為驗證嬰兒臉部偵測演算法之實際可行性，
將針對臉部偵測執行時間及偵測結果之準確度分別進行比較：
透過計算演算法偵測所有資料集共15416張影像所花費之時間，
得以算出各演算法平均每張需花費之時間；
而準確度則將嬰兒臉部偵測之影像結果進行分類標註，
分別計算出各演算法之accuracy、precision及recall。

\subsection{實驗結果與分析}
首先，針對演算法之執行時間進行比較，
透過實驗結果可得出使用SSD演算法進行嬰兒臉部偵測，
將可擁有較佳的偵測速度。
而四項演算法偵測15416張影像之詳細實驗結果如下：

（1）OpenCV演算法：
共花費18分01.78秒，
平均每張影像需花0.07秒；

（2）SSD演算法：
共花費9分17.26秒，
平均每張影像需花0.04秒；

（3）MTCNN演算法：
共花費2小時8分22.05秒，
平均每張影像需花0.50秒；

（4）RetinaFace演算法：
共花費5小時42分2.10秒，
平均每張影像需花1.33秒。

接著，就偵測之精確度進行比較，
透過實驗結果可得出選用RetinaFace演算法進行嬰兒臉部偵測，
可擁有較佳的偵測準確度。
而四項演算法進行嬰兒臉部偵測之詳細實驗結果如下：

（1）使用OpenCV演算法偵測結果如\cref{table:table-opencv}，
由於偵測效果不佳，
將多數影像皆誤判為False（無臉），
故僅計算其precision為79.90\%；

（2）使用SSD演算法偵測結果如\cref{table:table-ssd}，
由於偵測效果不佳，
將多數影像皆誤判為False（無臉），
故僅計算其precision為99.90\%；

（3）使用MTCNN演算法偵測結果如\cref{table:table-mtcnn}，
其accuracy為90.20\%、precision為94.76\%以及recall為90.93\%；

（4）使用RetinaFace演算法偵測結果如\cref{table:table-retinaface}，
其accuracy為99.78\%、precision為99.75\%以及recall為99.91\%。

綜觀上述兩部分實驗結果，
若系統欲擁有較迅速的執行速度又兼具偵測準確度，
可得出以下結論：
先使用SSD演算法找尋嬰兒臉部範圍，
雖然此方法在許多狀況未能如期找到嬰兒臉部範圍，
但其準確度很高，
故能利用此算法之時間優勢；
而若SSD演算法找不到嬰兒臉部時，
則接續使用RetinaFace演算法，
利用其很高之正確率及準確率之特質進行嬰兒臉部偵測。

\begin{table}[h]
    \centering
    \caption{OpenCV演算法偵測嬰兒臉部結果}
    \label{table:table-opencv}
    \begin{tabular}{ccc}
    \hline
     & True（預測有臉）& False（預測無臉）\\
    \hline
    True & \multirow{2}{*}{2882} & \multirow{4}{*}{11809} \\
    （實際有臉）& & \\
    False & \multirow{2}{*}{725} & \\
    （實際無臉）&  & \\
    \hline
    \end{tabular}
\end{table}

\begin{table}[h]
    \centering
    \caption{SSD演算法偵測嬰兒臉部結果}
    \label{table:table-ssd}
    \begin{tabular}{ccc}
    \hline
     & True（預測有臉）& False（預測無臉）\\
    \hline
    True & \multirow{2}{*}{4830} & \multirow{4}{*}{10581} \\
    （實際有臉）& & \\
    False & \multirow{2}{*}{5} & \\
    （實際無臉）&  & \\
    \hline
    \end{tabular}
\end{table}

\begin{table}[h]
    \centering
    \caption{MTCNN演算法偵測嬰兒臉部結果}
    \label{table:table-mtcnn}
    \begin{tabular}{ccc}
    \hline
     & True（預測有臉）& False（預測無臉）\\
    \hline
    True & \multirow{2}{*}{9361} & \multirow{2}{*}{994} \\
    （實際有臉）& & \\
    False & \multirow{2}{*}{517} & \multirow{2}{*}{4544} \\
    （實際無臉）&  & \\
    \hline
    Total & \textbf{9878} & \textbf{5538} \\
    \hline
    \end{tabular}
\end{table}

\begin{table}[h]
    \centering
    \caption{RetinaFace演算法偵測嬰兒臉部結果}
    \label{table:table-retinaface}
    \begin{tabular}{ccc}
    \hline
     & True（預測有臉）& False（預測無臉）\\
    \hline
    True & \multirow{2}{*}{12925} & \multirow{2}{*}{11} \\
    （實際有臉）& & \\
    False & \multirow{2}{*}{33} & \multirow{2}{*}{2447} \\
    （實際無臉）&  & \\
    \hline
    Total & \textbf{12958} & \textbf{2458} \\
    \hline
    \end{tabular}
\end{table}

\section{臉部遮擋辨識實驗}
\subsection{實驗目的與設計}
本系統為偵測嬰兒臉部是否遭非奶嘴之異物遮擋，
使用3.2節之資料集以ResNet50~\cite{he_deep_2016}
訓練模型，
並透過驗證集進行模型驗證。

程式實作中，
網路訓練回合數為20，
設定影像資料大小為224x224，
包含三個類別（臉部無遮擋之安全狀態、臉部遭奶嘴遮擋及臉部遭異物遮擋之危險狀態），
且透過data augmentation技術生成訓練及測試資料，
輸出層使用softmax作為激發函數，
並使用Adam作為優化器且將學習率設為0.000001以進行微調。

\subsection{實驗結果分析}
本實驗訓練之模型其最終訓練準確率達98.06\%，
而測試準確率達99.43\%，
詳細訓練結果請見\cref{fig:fig-result-face-occlusion}。
\fig[1][fig:fig-result-face-occlusion][!hbt]{fig-result-face-occlusion.png}[臉部辨識訓練結果][臉部辨識訓練結果]

接著，再使用342張之驗證集影像進行模型驗證，
所有影像皆辨識正確，
其混淆矩陣如\cref{fig:fig-confusion-matrix-face-occlusion}。
\fig[0.6][fig:fig-confusion-matrix-face-occlusion][!hbt]{fig-confusion-matrix-face-occlusion.png}[臉部遮擋辨識模型之混淆矩陣]

\section{姿勢辨識實驗}
\subsection{實驗目的與設計}
本系統為辨識嬰兒姿勢是否處於危險狀態，
使用3.3節之資料集以ResNet50~\cite{he_deep_2016}
訓練模型，
並透過驗證集進行模型驗證。

程式實作中，
網路訓練回合數為20，
設定影像資料大小為224x224，
包含四個類別（正躺、趴躺、坐姿及站立），
且透過data augmentation技術生成訓練及測試資料，
輸出層使用softmax作為激發函數，
並使用Adam作為優化器且將學習率設為0.000001以進行微調。

\subsection{實驗結果分析}
本實驗訓練之模型其最終訓練準確率達99.45\%，
而測試準確率達99.71\%，
詳細訓練結果請見\cref{fig:fig-result-four-classes}。
\fig[1][fig:fig-result-four-classes][!hbt]{fig-result-four-classes.png}[姿勢辨識訓練結果][姿勢辨識訓練結果]

接著，再使用744張之驗證集影像進行模型驗證，
包含了五張類別辨識錯誤的影像，
其混淆矩陣如\cref{fig:fig-confusion-matrix-four-classes}。
辨識錯誤之五張影像中，
有三張將坐姿誤判為趴躺姿勢，
推測原因為嬰兒雖呈現坐姿，
但上半身貼近其腿部（如\cref{fig:fig-error-four-classes}
），而導致誤判。
\fig[0.8][fig:fig-confusion-matrix-four-classes][!hbt]{fig-confusion-matrix-four-classes.png}[姿勢辨識模型之混淆矩陣]
\fig[0.6][fig:fig-error-four-classes][!hbt]{fig-error-four-classes.jpg}[姿勢辨識錯誤之影像：坐姿誤判為趴躺]

\section{影片危險偵測實驗}
\subsection{實驗目的與設計}
本實驗為驗證此系統能基於嬰兒影像進行危險監測，
利用網路之真實嬰兒影片，
包含不同之拍攝視角、嬰兒樣貌及狀態等，
實驗臉部遮擋辨識模型與姿勢辨識模型之準確性。

\subsection{實驗評估方式}
本實驗透過輸出每幀影像之臉部遮擋及姿勢辨識結果，
計算其accuracy、precision及recall，
以驗證此二模型得以應用在監測嬰兒危險情境。

\subsection{實驗結果分析}
本實驗影片為嬰兒正躺於畫面中，
並包含使用奶嘴及未使用奶嘴之情境，
共切成3374幀影像，
將未拍攝到嬰兒畫面之影像刪除後，
剩餘3307張嬰兒影像進行辨識。

首先，
姿勢辨識的部分，
包含了278張誤判為趴躺姿勢的影像，
推測原因為嬰兒身體遭棉被遮擋（如\cref{fig:fig-error-video-posture}），
而只拍攝到露出的嬰兒臉部，
故造成姿勢辨識錯誤，
其混淆矩陣如\cref{fig:fig-confusion-matrix-video-posture}。
\fig[0.6][fig:fig-error-video-posture][!hbt]{fig-error-video-posture.jpg}[姿勢辨識錯誤之影像：正躺誤判為趴躺]
\fig[0.8][fig:fig-confusion-matrix-video-posture][!hbt]{fig-confusion-matrix-video-posture.png}[實驗影片之姿勢辨識混淆矩陣]

其次，
臉部遮擋辨識的部分，
包含36張嬰兒臉部未被偵測之影像（如\cref{fig:fig-error-video-no-face}），
其中多張影像類別應為嬰兒正在使用奶嘴或安全狀態，
但誤判為遭異物遮蔽之警示狀態，
推測原因為影像中之奶嘴或嬰兒臉部遭手部等遮擋（如\cref{fig:fig-error-video-face}），
而誤判為類別，
其混淆矩陣如\cref{fig:fig-confusion-matrix-video-face}。
\fig[0.6][fig:fig-error-video-no-face][!hbt]{fig-error-video-no-face.jpg}[未偵測嬰兒臉部之影像]
\fig[0.4][fig:fig-error-video-face][!hbt]{fig-error-video-face.jpg}[臉部遮擋誤判之為警示狀態]
\fig[0.8][fig:fig-confusion-matrix-video-face][!hbt]{fig-confusion-matrix-video-face.png}[實驗影片之臉部遮擋辨識混淆矩陣]

\end{document}