
@article{kinney_sudden_2009,
	title = {The {Sudden} {Infant} {Death} {Syndrome}},
	volume = {361},
	issn = {0028-4793},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3268262/},
	doi = {10.1056/NEJMra0803836},
	number = {8},
	urldate = {2022-05-31},
	journal = {The New England Journal of Medicine},
	author = {Kinney, Hannah C. and Thach, Bradley T.},
	month = aug,
	year = {2009},
	pmid = {19692691},
	pmcid = {PMC3268262},
	pages = {795--805},
	file = {接受的版本:C\:\\Users\\chiachun.wang\\Zotero\\storage\\4SDSY33P\\Kinney 與 Thach - 2009 - The Sudden Infant Death Syndrome.pdf:application/pdf},
}

@inproceedings{linti_sensory_2006,
	title = {Sensory baby vest for the monitoring of infants},
	doi = {10.1109/BSN.2006.49},
	abstract = {Continuous monitoring of physiological parameters is very often necessary for the evaluation of health conditions, diagnostic reasons and the detection of life or health threatening events. For infants, especially, who cannot provide any feedback about discomfort or health complaints it is an important issue to collect objective data under everyday conditions. The demand of physicians for the development of monitoring and diagnostic systems which are easier to handle and less obtrusive than the commonly used medical systems was the motivation for the presented project. Another motivation was the concern frequently expressed by parents about the danger of apparently life threatening events (ALTE) or even the problems of sudden infants death syndrome (SIDS). The developed sensory baby vest includes fully integrated sensors for the parameters respiration, heart rate, temperature and humidity, to detect excessive sweating, for the continuous monitoring of infants under clinical and home conditions. It will allow the early detection of potential life threatening events calling for rescue as well as the recognition of the development or progression of diseases at an early stage. Health protection or even life-saving thus will be enabled in time. A variety of principles for the measurement of the parameters has been assessed for the integration into garments. Prototypes have been manufactured incorporating the chosen sensing principles with textile and textile-compatible technologies. Currently, the prototypes are clinically tested for durability, handling and signal quality.},
	booktitle = {International {Workshop} on {Wearable} and {Implantable} {Body} {Sensor} {Networks} ({BSN}'06)},
	author = {Linti, C. and Horter, H. and Osterreicher, P. and Planck, H.},
	month = apr,
	year = {2006},
	note = {ISSN: 2376-8894},
	keywords = {Biomedical monitoring, Condition monitoring, Event detection, Feedback, Heart rate, Humidity, Medical diagnostic imaging, Pediatrics, Prototypes, Temperature sensors},
	pages = {3 pp.--137},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\chiachun.wang\\Zotero\\storage\\7BIIX5L2\\1612914.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\chiachun.wang\\Zotero\\storage\\8F2KR36W\\Linti 等。 - 2006 - Sensory baby vest for the monitoring of infants.pdf:application/pdf},
}

@inproceedings{ferreira_smart_2016,
	title = {A smart wearable system for sudden infant death syndrome monitoring},
	doi = {10.1109/ICIT.2016.7475060},
	abstract = {Sudden Infant Death Syndrome (SIDS) is one of the major causes of death among infants during their sleep. To increase the safety of the infants, we matched different emergent research fields for the development of Baby Night Watch. This Smart Wearable System (SWS), developed under the context of the European Texas Instruments Innovation Challenge (TIIC) 2015, is composed by the following elements: a Wearable IoT Device, a Gateway and the H Medical Interface. The Wearable IoT Device is a wireless sensor node integrated in a Chest Belt, and it has the capacity to monitor the following parameters: body temperature, heart and breathing rates and body position. After a minimal data processing, this set of information is sent to the Gateway, via ZigBee technology, and it is accessible to the user through the H Medical Interface. If a critical event occurs, the device will trigger an alarm, visible and audible in the proximity, and sends a distress message to a mobile application. The Baby Night Watch is an important tool for medical studies, since it allows the visualization of previous physiological data and export it to different types of datasets. Experimental tests have proven that the SWS has the potential to identify situations that could be potentially life-threatening for an infant.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Industrial} {Technology} ({ICIT})},
	author = {Ferreira, André G. and Fernandes, Duarte and Branco, Sérgio and Monteiro, João L. and Cabral, Jorge and Catarino, André P. and Rocha, Ana M.},
	month = mar,
	year = {2016},
	keywords = {Biomedical monitoring, Heart rate, Pediatrics, Temperature sensors, E-textile, Electrodes, Internet of Things, Monitoring, Smart Textiles, Smart Wearable System, Sudden Infant Death Syndrome, Textiles},
	pages = {1920--1925},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\chiachun.wang\\Zotero\\storage\\4MMYZMMU\\7475060.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\chiachun.wang\\Zotero\\storage\\QVMNFIHZ\\Ferreira 等。 - 2016 - A smart wearable system for sudden infant death sy.pdf:application/pdf},
}

@inproceedings{ziganshin_uwb_2010,
	title = {{UWB} {Baby} {Monitor}},
	doi = {10.1109/UWBUSIS.2010.5609156},
	abstract = {A successful case for UWB technology application to Vital Signs Monitoring Systems created by authors is presented in this paper. Baby Monitor for remote contactless monitoring of respiratory and heart rate is designed both for consumer and medical infant monitoring applications. Unlike conventional sound- and video-based baby monitors, which do not provide any useful information at infant sleep time (no sounds or static picture) the devices allow permanent parental control and effectively prevent Sudden Infant Death Syndrome (SIDS) from occurring. SIDS is reported to be leading death cause of healthy infants after one month age.},
	booktitle = {2010 5th {International} {Confernce} on {Ultrawideband} and {Ultrashort} {Impulse} {Signals}},
	author = {Ziganshin, E. G. and Numerov, M. A. and Vygolov, S. A.},
	month = sep,
	year = {2010},
	keywords = {Biomedical monitoring, Pediatrics, Monitoring, Frequency modulation, Infant incubator, Medical Radar, Newborn, Respiration, Sleep apnea, Sleep apnea syndrome, Sudden infant death syndrome, Ultra wideband technology, Ultra-Wide Band},
	pages = {159--161},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\chiachun.wang\\Zotero\\storage\\5XK448W7\\5609156.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\chiachun.wang\\Zotero\\storage\\L4XKX6BH\\Ziganshin 等。 - 2010 - UWB Baby Monitor.pdf:application/pdf},
}

@inproceedings{fang_vision-based_2015,
	title = {A {Vision}-{Based} {Infant} {Respiratory} {Frequency} {Detection} {System}},
	doi = {10.1109/DICTA.2015.7371224},
	abstract = {Sudden infant death syndrome (SIDS) is the major cause of death for infants aged one week to twelve months. The SIDS rate has declined owing to the awareness of caregivers and parents, but the rate is still high even in developed countries because of the difficulty in rescuing the infant immediately. Respiration, which can reflect various physiological conditions, is a basic but vital function for infants. Therefore, this study presents a respiration monitoring system with a video camera positioned in front of an infant to non-invasively detect the infant's respiratory frequency. The proposed system can continuously monitor the infant to detect unusual occurrences in the infant's respiration, to alert caregivers to attend to the infant immediately and reduce potential injuries from SIDS and other respiratory-related disease. The proposed system contains four major stages, including motion detection, candidate point extraction, respiration point selection, and respiratory frequency calculation. During motion detection the system captures images from video and decides whether to conduct the following stages. If no obvious motion is detected in the input frames, then SIDS may have occurred in the infant, and the system extracts candidate points by some spatial characteristics. Based on these points, the system then selects respiration points using a fuzzy integral technique with four temporal characteristics, including entropy, period, skewness, and kurtosis. Finally, the infant's respiratory frequency is calculated. Experimental data are obtained from ten infants, in 48 sequences with a total length of 150 minutes. The experimental results show that the proposed system is robust and efficient.},
	booktitle = {2015 {International} {Conference} on {Digital} {Image} {Computing}: {Techniques} and {Applications} ({DICTA})},
	author = {Fang, Chiung-Yao and Hsieh, Hsin-Hung and Chen, Sei-Wang},
	month = nov,
	year = {2015},
	keywords = {Pediatrics, Monitoring, Sleep apnea, Flowcharts, Motion detection, Sensors, Visualization},
	pages = {1--8},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\chiachun.wang\\Zotero\\storage\\TFIWLR6Z\\7371224.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\chiachun.wang\\Zotero\\storage\\ZB2N5TDQ\\Fang 等。 - 2015 - A Vision-Based Infant Respiratory Frequency Detect.pdf:application/pdf},
}

@inproceedings{liu_video-based_2017,
	title = {Video-based {IoT} baby monitor for {SIDS} prevention},
	doi = {10.1109/GHTC.2017.8239258},
	abstract = {Sudden Infant Death Syndrome, also known as SIDS, is the leading cause of mortality in infants from one month to one year of age. We propose a video-based baby monitoring system with Internet of Things (IoT) capabilities to help shorten the response time of SIDS cases. Using a video amplification technique developed at MIT dubbed “Eulerian Magnification” to amplify subtle movements, we can compare pixel color differences in frames for breathing detection in a recorded video of a baby. When abnormal movement is detected from the baby, an alarm will be generated to notify the parents or guardians. The expected accuracy is over 98\% for a baby monitor that is intended to be a noninvasive, low cost and efficient solution. The major monitoring situation we considered is during night time, therefore we used a night vision camera for the tests. The camera frame was focused in the size of a crib, and hence there is no concern about losing the sight of the infant which would cause monitoring failure. Currently our team has accomplished the algorithm design and alarm generating design. We consider that making it works in real-time and on an independent IoT board are the future work to complete this project.},
	booktitle = {2017 {IEEE} {Global} {Humanitarian} {Technology} {Conference} ({GHTC})},
	author = {Liu, Xiaoting and Takeuchi, Kyle and Ogunfunmi, Tokunbo and Mathapathi, Shivakumar},
	month = oct,
	year = {2017},
	keywords = {Pediatrics, Monitoring, Cameras, Frequency-domain analysis, Low pass filters, MATLAB, Night vision},
	pages = {1--7},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\chiachun.wang\\Zotero\\storage\\EANH23W9\\8239258.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\chiachun.wang\\Zotero\\storage\\3KTD4WEI\\Liu 等。 - 2017 - Video-based IoT baby monitor for SIDS prevention.pdf:application/pdf},
}

@inproceedings{gallo_marrsids_2019,
	title = {{MARRSIDS}: {Monitoring} {Assistant} to {Reduce} the {Risk} of {Sudden} {Infant} {Death} {Syndrome}},
	shorttitle = {{MARRSIDS}},
	doi = {10.1109/STSIVA.2019.8730261},
	abstract = {One of the main causes of death in children, during the first year of life, is Sudden Infant Death Syndrome (SIDS) due to the poor position of the infant when sleeping. In this work a prototype is proposed, called MARRSIDS, based on elements of accessible hardware, free software and artificial vision that allows to monitor the infant, while she/he sleeps. The monitoring assintant executes a sound alarm if it identifies that the child is in an incorrect position. To verify the reliability of the device, experiments are included in children, with different characteristics, that have been monitored during a certain period of time in which the behavior of the device has proven to be effective.},
	booktitle = {2019 {XXII} {Symposium} on {Image}, {Signal} {Processing} and {Artificial} {Vision} ({STSIVA})},
	author = {Gallo, Xavier López and Lechón, Santiago and Mora, Stalin and Vallejo-Huanga, Diego},
	month = apr,
	year = {2019},
	note = {ISSN: 2329-6259},
	keywords = {Pediatrics, Prototypes, Monitoring, Sudden Infant Death Syndrome, Cameras, Artificial Vision, Face, Hardware, OpenCV, Pattern Recognition, Software},
	pages = {1--4},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\chiachun.wang\\Zotero\\storage\\T4KGFN5C\\8730261.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\chiachun.wang\\Zotero\\storage\\KQ87CJ7R\\Gallo 等。 - 2019 - MARRSIDS Monitoring Assistant to Reduce the Risk .pdf:application/pdf},
}

@inproceedings{wang_multi-task_2019,
	title = {A {Multi}-{Task} {Bayesian} {Deep} {Neural} {Net} for {Detecting} {Life}-{Threatening} {Infant} {Incidents} {From} {Head} {Images}},
	doi = {10.1109/ICIP.2019.8803332},
	abstract = {The notorious incident of sudden infant death syndrome (SIDS) can easily happen to a newborn due to many environmental factors. To prevent such tragic incidents from happening, we propose a multi-task deep learning framework that detects different facial traits and two life-threatening indicators, i.e. which facial parts are occluded or covered, by analyzing the infant head image. Furthermore, we extend and adapt the recently developed models that capture data-dependent uncertainty from noisy observations for our application. The experimental results show significant improvements on YunInfants dataset across most of the tasks over the models that simply adopt the regular cross-entropy losses without addressing the effect of the underlying uncertainties.},
	booktitle = {2019 {IEEE} {International} {Conference} on {Image} {Processing} ({ICIP})},
	author = {Wang, Tzu-Jui and Laaksonen, Jorma and Liao, Yi-Ping and Wu, Bo-Zong and Shen, Shih-Yun},
	month = sep,
	year = {2019},
	note = {ISSN: 2381-8549},
	keywords = {Pediatrics, Bayes methods, Bayesian deep neural net, cover detection, Mouth, neonate safety, Nose, occlusion detection, Task analysis, Uncertainty},
	pages = {3006--3010},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\chiachun.wang\\Zotero\\storage\\HL276FQG\\Wang 等。 - 2019 - A Multi-Task Bayesian Deep Neural Net for Detectin.pdf:application/pdf},
}

@inproceedings{bharati_efficient_2021,
	title = {An {Efficient} {Edge} {Deep} {Learning} {Computer} {Vision} {System} to {Prevent} {Sudden} {Infant} {Death} {Syndrome}},
	doi = {10.1109/SMARTCOMP52413.2021.00061},
	abstract = {Sudden Infant Death Syndrome (SIDS) causes infants under one year of age to die inexplicably. One of the most important external factors, also called an "outside stressor," that is responsible for Sudden Infant Death Syndrome (SIDS), is the sleeping position of the baby. According to past research, the risk of SIDS increases when the baby sleeps facedown on the stomach. We propose a Convolutional Neural Network (CNN) based computer-vision system that estimates the sleeping pose of the baby and alerts caregivers on their mobile phones within a few seconds of the baby moving to the hazardous facedown sleeping position. The system has a low computational load and a low memory footprint. This characteristic allows the system to be embedded in low power edge devices such as certain baby monitors. Processing at the edge also alleviates privacy concerns with regards to sending images into the network. We experimented with various numbers of convolutional processing units and dense layers as well as the number of convolutional kernels to arrive at the optimal production configuration. We observed a consistently high accuracy of detection of infant sleeping position changes from turning to facedown positions with a potential towards even higher accuracies with caregiver feedback for model retraining. Therefore, this system is a viable candidate for consideration as a non-intrusive solution to assist in preventing SIDS.},
	booktitle = {2021 {IEEE} {International} {Conference} on {Smart} {Computing} ({SMARTCOMP})},
	author = {Bharati, Vivek},
	month = aug,
	year = {2021},
	note = {ISSN: 2693-8340},
	keywords = {Pediatrics, Sudden Infant Death Syndrome, Computational modeling, convolutional neural network, Death, Deep learning, edge deep learning, image classification, Image edge detection, Mobile handsets, posture estimation, SIDS, Turning},
	pages = {286--291},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\chiachun.wang\\Zotero\\storage\\RQZQCWXW\\9556293.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\chiachun.wang\\Zotero\\storage\\5UDF7FTM\\Bharati - 2021 - An Efficient Edge Deep Learning Computer Vision Sy.pdf:application/pdf},
}

@inproceedings{lin_wireless_2014,
	title = {Wireless {Infant} {Monitoring} {Device} for the prevention of sudden infant death syndrome},
	doi = {10.1109/CEWIT.2014.7021146},
	abstract = {A wireless Infant Monitoring Device has been developed as a preventive measure against sudden infant death syndrome. It measures the sleep position, respiratory rate and body temperature of an infant as well as its surrounding carbon monoxide concentration. Those data are considered as the risk factors of the sudden infant death syndrome. They are analyzed on board and results are transmitted to a remote server via Wi-Fi. Alarms will be triggered if any of the monitored parameters is beyond the preset limits. The system was tested on an infant manikin driven by an infant ventilator. Test outcomes demonstrated that it can reliably measure respiratory rate down to the low respiratory pressure of 3 mmHg peak to peak in addition to the infant position, temperature and carbon monoxide concentration. The device can be easily integrated into cloud service to enhance its features with its wireless communication capabilities.},
	booktitle = {2014 11th {International} {Conference} {Expo} on {Emerging} {Technologies} for a {Smarter} {World} ({CEWIT})},
	author = {Lin, Wei and Zhang, Ruikai and Brittelli, John and Lehmann, Craig},
	month = oct,
	year = {2014},
	keywords = {Pediatrics, Monitoring, Sudden Infant Death Syndrome, eHealth, microcontroller, Microcontrollers, Servers, Temperature measurement, Wi-Fi, wireless communication, Wireless communication, wireless healthcare, Wireless sensor networks},
	pages = {1--4},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\chiachun.wang\\Zotero\\storage\\6CXI777F\\7021146.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\chiachun.wang\\Zotero\\storage\\I28CBZ2T\\Lin 等。 - 2014 - Wireless Infant Monitoring Device for the preventi.pdf:application/pdf},
}

@inproceedings{deng_retinaface_2020,
	title = {{RetinaFace}: {Single}-{Shot} {Multi}-{Level} {Face} {Localisation} in the {Wild}},
	shorttitle = {{RetinaFace}},
	doi = {10.1109/CVPR42600.2020.00525},
	abstract = {Though tremendous strides have been made in uncontrolled face detection, accurate and efficient 2D face alignment and 3D face reconstruction in-the-wild remain an open challenge. In this paper, we present a novel single-shot, multi-level face localisation method, named RetinaFace, which unifies face box prediction, 2D facial landmark localisation and 3D vertices regression under one common target: point regression on the image plane. To fill the data gap, we manually annotated five facial landmarks on the WIDER FACE dataset and employed a semi-automatic annotation pipeline to generate 3D vertices for face images from the WIDER FACE, AFLW and FDDB datasets. Based on extra annotations, we propose a mutually beneficial regression target for 3D face reconstruction, that is predicting 3D vertices projected on the image plane constrained by a common 3D topology. The proposed 3D face reconstruction branch can be easily incorporated, without any optimisation difficulty, in parallel with the existing box and 2D landmark regression branches during joint training. Extensive experimental results show that RetinaFace can simultaneously achieve stable face detection, accurate 2D face alignment and robust 3D face reconstruction while being efficient through single-shot inference.},
	booktitle = {2020 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Deng, Jiankang and Guo, Jia and Ververas, Evangelos and Kotsia, Irene and Zafeiriou, Stefanos},
	month = jun,
	year = {2020},
	note = {ISSN: 2575-7075},
	keywords = {Face, Task analysis, Face detection, Image reconstruction, Three-dimensional displays, Training, Two dimensional displays},
	pages = {5202--5211},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\chiachun.wang\\Zotero\\storage\\FZKTUA9A\\9157330.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\chiachun.wang\\Zotero\\storage\\SV6F65U7\\Deng 等。 - 2020 - RetinaFace Single-Shot Multi-Level Face Localisat.pdf:application/pdf},
}

@misc{__2021,
	type = {文字},
	title = {歷年統計},
	copyright = {統計處},
	url = {https://dep.mohw.gov.tw/DOS/lp-5069-113.html},
	abstract = {歷年統計},
	language = {中文},
	urldate = {2022-05-31},
	journal = {統計處},
	author = {統計處},
	month = mar,
	year = {2021},
	note = {Publisher: 統計處},
	file = {Snapshot:C\:\\Users\\chiachun.wang\\Zotero\\storage\\W58YVNF7\\lp-5069-113.html:text/html},
}

@inproceedings{he_deep_2016,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	doi = {10.1109/CVPR.2016.90},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = jun,
	year = {2016},
	note = {ISSN: 1063-6919},
	keywords = {Visualization, Training, Neural networks, Complexity theory, Degradation, Image recognition, Image segmentation},
	pages = {770--778},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\chiachun.wang\\Zotero\\storage\\ZFGHNWLD\\7780459.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\chiachun.wang\\Zotero\\storage\\QIKZM3FA\\He 等。 - 2016 - Deep Residual Learning for Image Recognition.pdf:application/pdf},
}

@inproceedings{ye_face_2021,
	title = {Face {SSD}: {A} {Real}-time {Face} {Detector} based on {SSD}},
	shorttitle = {Face {SSD}},
	doi = {10.23919/CCC52363.2021.9550294},
	abstract = {Face detection has made substantial progress in recent years. In many applications, face detectors must run on mobile devices or embedded devices. Due to the limited computing resource in such scenarios, it is usually difficult to meet the need of both accuracy and speed. Most detectors cannot detect small face accurately or the detection speed will slow down. To address this challenge, we propose a novel face detector in which the basic framework is a single shot multibox detector (SSD), and name it Face SSD. In order to accelerate the detection speed of Face SSD and improve the detection accuracy, we make contributions in the following three aspects: we improved the structure of ShuffleNet V2 and use it as the backbone network; then we proposed a modified prediction module (MPM) to improve recall of small faces; finally we introduced a scale-equitable face detection framework to match face better. Experimental results show that Face SSD runs 40 frames per second (FPS) on CPU and 110 FPS on GPU. We train Face SSD on WIDER FACE - a face detection benchmark. The detector has also achieved excellent performance on FDDB, a benchmark for face detection in unconstrained settings.},
	booktitle = {2021 40th {Chinese} {Control} {Conference} ({CCC})},
	author = {Ye, Bin and Shi, Yunlin and Li, Huijun and Li, Liuchuan and Tong, Shuo},
	month = jul,
	year = {2021},
	note = {ISSN: 1934-1768},
	keywords = {Computational modeling, Benchmark testing, Convolution, Detectors, Face Detector, Graphics processing units, MPM, Performance evaluation, Real-time, Real-time systems, ShuffleNet V2, SSD},
	pages = {8445--8450},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\chiachun.wang\\Zotero\\storage\\QAX7D5H7\\9550294.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\chiachun.wang\\Zotero\\storage\\8MTKK7AX\\Ye 等。 - 2021 - Face SSD A Real-time Face Detector based on SSD.pdf:application/pdf},
}

@inproceedings{goyal_face_2017,
	title = {Face detection and tracking: {Using} {OpenCV}},
	volume = {1},
	shorttitle = {Face detection and tracking},
	doi = {10.1109/ICECA.2017.8203730},
	abstract = {An application for tracking and detecting faces in videos and in cameras which can be used for multipurpose activities. The intention of the paper is deep study of face detection using open CV. A tabular comparison is performed in order to understand the algorithms in an easier manner. It talks about various algorithms like Adaboost, Haar cascades. This paper aims to help in understanding the best prerequisites for face detection.},
	booktitle = {2017 {International} conference of {Electronics}, {Communication} and {Aerospace} {Technology} ({ICECA})},
	author = {Goyal, Kruti and Agarwal, Kartikey and Kumar, Rishi},
	month = apr,
	year = {2017},
	keywords = {Cameras, MATLAB, Face, Face detection, Face recognition, Adaboost (adaptive boost), Image color analysis, open computer vision (OpenCV), Skin},
	pages = {474--478},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\chiachun.wang\\Zotero\\storage\\MKRUJ7FH\\8203730.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\chiachun.wang\\Zotero\\storage\\LUTFBJTP\\Goyal 等。 - 2017 - Face detection and tracking Using OpenCV.pdf:application/pdf},
}

@article{zhang_joint_2016,
	title = {Joint {Face} {Detection} and {Alignment} {Using} {Multitask} {Cascaded} {Convolutional} {Networks}},
	volume = {23},
	issn = {1558-2361},
	doi = {10.1109/LSP.2016.2603342},
	abstract = {Face detection and alignment in unconstrained environment are challenging due to various poses, illuminations, and occlusions. Recent studies show that deep learning approaches can achieve impressive performance on these two tasks. In this letter, we propose a deep cascaded multitask framework that exploits the inherent correlation between detection and alignment to boost up their performance. In particular, our framework leverages a cascaded architecture with three stages of carefully designed deep convolutional networks to predict face and landmark location in a coarse-to-fine manner. In addition, we propose a new online hard sample mining strategy that further improves the performance in practice. Our method achieves superior accuracy over the state-of-the-art techniques on the challenging face detection dataset and benchmark and WIDER FACE benchmarks for face detection, and annotated facial landmarks in the wild benchmark for face alignment, while keeps real-time performance.},
	number = {10},
	journal = {IEEE Signal Processing Letters},
	author = {Zhang, Kaipeng and Zhang, Zhanpeng and Li, Zhifeng and Qiao, Yu},
	month = oct,
	year = {2016},
	note = {Conference Name: IEEE Signal Processing Letters},
	keywords = {Face, Face detection, Training, face detection, Benchmark testing, Convolution, Detectors, Cascaded convolutional neural network (CNN), Computer architecture, face alignment},
	pages = {1499--1503},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\chiachun.wang\\Zotero\\storage\\9PS6UFQQ\\7553523.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\chiachun.wang\\Zotero\\storage\\IEGMTHGF\\Zhang 等。 - 2016 - Joint Face Detection and Alignment Using Multitask.pdf:application/pdf},
}

@inproceedings{tang_hands_2008,
	title = {Hand's {Skin} {Detection} {Based} on {Ellipse} {Clustering}},
	volume = {2},
	doi = {10.1109/ISCSCT.2008.53},
	abstract = {Skin color model is an important method in skin color detection. This paper introduced the process of building skin color model based on ellipse clustering and detection to image with this skin color model. Before the skin color model building, we analysed color space and chose lighten-unrelated YCbCr space. Because of the effect of environment when get the image, we compensated illumination with logarithm transformation and filter the right light based on statistic. Also, in order to improve the detecting efficiency, we import an ponderance named Ct to present the number of skin pixels. If Ct lower than a threshold, we look it as non-skin pixels. The experiment proved that this skin color model can detect the skin pixels more effectively and have high robust. Compared to the traditional skin color model such as regional model, single gauss model etc, the algorithmical complexity, detecting rate and error detect rate have evident improvement.},
	booktitle = {2008 {International} {Symposium} on {Computer} {Science} and {Computational} {Technology}},
	author = {Tang, Hao-kui and Feng, Zhi-quan},
	month = dec,
	year = {2008},
	keywords = {Face detection, Image color analysis, Skin, Biological system modeling, Clustering algorithms, compesate, Computer vision, Educational institutions, ellipse cluster, Information science, Lighting, Robustness, skin color model},
	pages = {758--761},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\chiachun.wang\\Zotero\\storage\\6CXMG7VZ\\references.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\chiachun.wang\\Zotero\\storage\\99W4JHIC\\Tang 與 Feng - 2008 - Hand's Skin Detection Based on Ellipse Clustering.pdf:application/pdf},
}

@inproceedings{li_face_2011,
	title = {Face detection algorithm based on double ellipse skin model},
	doi = {10.1109/ICSESS.2011.5982231},
	abstract = {In this paper, we develop a novel face detection algorithm for color image in conditions of varying lighting, complex backgrounds and multiple faces. This algorithm relys on a four step process: First, preprocessing the color input image by color bias correction and light compensation and equalization. Second, segmenting and extracting the skin region based on CbCr-CgCr double ellipse skin model. Third, postprocessing the segmented skin image by morphological denoising and facial features holes filling. Finally, locating face region by using AdaBoost cascade classifier and detecting facial features by making use of face geometric and gradient characteristics. Experiment results show that the effectiveness of our algorithm.},
	booktitle = {2011 {IEEE} 2nd {International} {Conference} on {Software} {Engineering} and {Service} {Science}},
	author = {Li, Wei and Yang, Qinghua and He, Xianbo},
	month = jul,
	year = {2011},
	note = {ISSN: 2327-0594},
	keywords = {Face detection, color bias correction, face localization, skin model},
	pages = {335--339},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\chiachun.wang\\Zotero\\storage\\U8PSKA5M\\5982231.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\chiachun.wang\\Zotero\\storage\\N7ELJ6M6\\Li 等。 - 2011 - Face detection algorithm based on double ellipse s.pdf:application/pdf},
}

@misc{noauthor_python_nodate,
	title = {python opencv膚色檢測的實現示例\_程式設計\_程式人生},
	url = {https://www.796t.com/article.php?id=196625},
	urldate = {2022-06-09},
	file = {python opencv膚色檢測的實現示例_程式設計_程式人生:C\:\\Users\\chiachun.wang\\Zotero\\storage\\THI7Z87R\\article.html:text/html},
}

@misc{walkonnet_python_nodate,
	title = {python opencv膚色檢測的實現示例 – {WalkonNet}},
	url = {https://walkonnet.com/archives/7903},
	language = {zh-TW},
	urldate = {2022-06-09},
	author = {{WalkonNet}},
	file = {Snapshot:C\:\\Users\\chiachun.wang\\Zotero\\storage\\PW26JZM5\\7903.html:text/html},
}

@misc{noauthor_what_nodate,
	title = {What causes {SIDS}?},
	url = {https://www.nichd.nih.gov/health/topics/sids/conditioninfo/causes},
	abstract = {Health care providers and researchers don't know the exact cause, but there are many theories. More and more research evidence suggests that infants who die from sudden infant death syndrome (SIDS) are born with brain abnormalities or defects. These defects are typically found within a network of nerve cells that rely on a chemical called serotonin that allows one nerve cell to send a signal to another nerve cell. The cells are located in the part of the brain that probably controls breathing, heart rate, blood pressure, temperature, and waking from sleep.},
	language = {en},
	urldate = {2022-06-21},
	journal = {https://www.nichd.nih.gov/},
	file = {Snapshot:C\:\\Users\\chiachun.wang\\Zotero\\storage\\Z7NTWXPH\\causes.html:text/html},
}

@misc{simonyan_very_2015,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1409.1556},
	doi = {10.48550/arXiv.1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	urldate = {2022-06-22},
	publisher = {arXiv},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = apr,
	year = {2015},
	note = {Number: arXiv:1409.1556
arXiv:1409.1556 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\chiachun.wang\\Zotero\\storage\\Q3WK5DAN\\Simonyan 與 Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\chiachun.wang\\Zotero\\storage\\ZQLQMABI\\1409.html:text/html},
}

@inproceedings{szegedy_going_2015,
	title = {Going deeper with convolutions},
	doi = {10.1109/CVPR.2015.7298594},
	abstract = {We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
	booktitle = {2015 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	month = jun,
	year = {2015},
	note = {ISSN: 1063-6919},
	keywords = {Visualization, Neural networks, Computer architecture, Computer vision, Convolutional codes, Object detection, Sparse matrices},
	pages = {1--9},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\chiachun.wang\\Zotero\\storage\\PS8XXN93\\7298594.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\chiachun.wang\\Zotero\\storage\\N7K3JXET\\Szegedy 等。 - 2015 - Going deeper with convolutions.pdf:application/pdf},
}

@misc{ioffe_batch_2015,
	title = {Batch {Normalization}: {Accelerating} {Deep} {Network} {Training} by {Reducing} {Internal} {Covariate} {Shift}},
	shorttitle = {Batch {Normalization}},
	url = {http://arxiv.org/abs/1502.03167},
	doi = {10.48550/arXiv.1502.03167},
	abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.},
	urldate = {2022-06-22},
	publisher = {arXiv},
	author = {Ioffe, Sergey and Szegedy, Christian},
	month = mar,
	year = {2015},
	note = {Number: arXiv:1502.03167
arXiv:1502.03167 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\chiachun.wang\\Zotero\\storage\\PR38NXGA\\Ioffe 與 Szegedy - 2015 - Batch Normalization Accelerating Deep Network Tra.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\chiachun.wang\\Zotero\\storage\\FVW3GJQM\\1502.html:text/html},
}

@article{zhang_single-shot_2019,
	title = {Single-{Shot} {Scale}-{Aware} {Network} for {Real}-{Time} {Face} {Detection}},
	volume = {127},
	issn = {1573-1405},
	url = {https://doi.org/10.1007/s11263-019-01159-3},
	doi = {10.1007/s11263-019-01159-3},
	abstract = {In this work, we describe a single-shot scale-aware convolutional neural network based face detector (SFDet). In comparison with the state-of-the-art anchor-based face detection methods, the main advantages of our method are summarized in four aspects. (1) We propose a scale-aware detection network using a wide scale range of layers associated with appropriate scales of anchors to handle faces with various scales, and describe a new equal density principle to ensure anchors with different scales to be evenly distributed on the image. (2) To improve the recall rates of faces with certain scales (e.g., the scales of the faces are quite different from the scales of designed anchors), we design a new anchor matching strategy with scale compensation. (3) We introduce an IoU-aware weighting scheme for each training sample in classification loss calculation to encode samples accurately in training process. (4) Considering the class imbalance issue, a max-out background strategy is used to reduce false positives. Several experiments are conducted on public challenging face detection datasets, i.e., WIDER FACE, AFW, PASCAL Face, FDDB, and MAFA, to demonstrate that the proposed method achieves the state-of-the-art results and runs at 82.1 FPS for the VGA-resolution images.},
	language = {en},
	number = {6},
	urldate = {2022-06-22},
	journal = {International Journal of Computer Vision},
	author = {Zhang, Shifeng and Wen, Longyin and Shi, Hailin and Lei, Zhen and Lyu, Siwei and Li, Stan Z.},
	month = jun,
	year = {2019},
	keywords = {Face detection, Class imbalance, Scale-aware, Single-shot},
	pages = {537--559},
}

@misc{cao_openpose_2019,
	title = {{OpenPose}: {Realtime} {Multi}-{Person} {2D} {Pose} {Estimation} using {Part} {Affinity} {Fields}},
	shorttitle = {{OpenPose}},
	url = {http://arxiv.org/abs/1812.08008},
	doi = {10.48550/arXiv.1812.08008},
	abstract = {Realtime multi-person 2D pose estimation is a key component in enabling machines to have an understanding of people in images and videos. In this work, we present a realtime approach to detect the 2D pose of multiple people in an image. The proposed method uses a nonparametric representation, which we refer to as Part Affinity Fields (PAFs), to learn to associate body parts with individuals in the image. This bottom-up system achieves high accuracy and realtime performance, regardless of the number of people in the image. In previous work, PAFs and body part location estimation were refined simultaneously across training stages. We demonstrate that a PAF-only refinement rather than both PAF and body part location refinement results in a substantial increase in both runtime performance and accuracy. We also present the first combined body and foot keypoint detector, based on an internal annotated foot dataset that we have publicly released. We show that the combined detector not only reduces the inference time compared to running them sequentially, but also maintains the accuracy of each component individually. This work has culminated in the release of OpenPose, the first open-source realtime system for multi-person 2D pose detection, including body, foot, hand, and facial keypoints.},
	urldate = {2022-06-24},
	publisher = {arXiv},
	author = {Cao, Zhe and Hidalgo, Gines and Simon, Tomas and Wei, Shih-En and Sheikh, Yaser},
	month = may,
	year = {2019},
	note = {Number: arXiv:1812.08008
arXiv:1812.08008 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Journal version of arXiv:1611.08050, with better accuracy and faster speed, release a new foot keypoint dataset: https://cmu-perceptual-computing-lab.github.io/foot\_keypoint\_dataset/},
	file = {arXiv Fulltext PDF:C\:\\Users\\chiachun.wang\\Zotero\\storage\\49KPA28N\\Cao 等。 - 2019 - OpenPose Realtime Multi-Person 2D Pose Estimation.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\chiachun.wang\\Zotero\\storage\\PYWXWLNB\\1812.html:text/html},
}

@misc{noauthor_pose_nodate,
	title = {Pose},
	url = {https://google.github.io/mediapipe/solutions/pose.html},
	abstract = {Cross-platform, customizable ML solutions for live and streaming media.},
	language = {en-US},
	urldate = {2022-06-24},
	journal = {mediapipe},
	file = {Snapshot:C\:\\Users\\chiachun.wang\\Zotero\\storage\\WPQHSYR4\\pose.html:text/html},
}
